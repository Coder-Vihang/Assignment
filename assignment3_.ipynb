{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment3 .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPH0ifRreWkaDSOQgZu7LFb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Coder-Vihang/Assignment/blob/main/assignment3_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5_id4iwkYBA"
      },
      "source": [
        "import argparse"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv7r3J3DlSEI"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r8_007Tls5Y"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl1PeCmaqB9h"
      },
      "source": [
        "df=pd.read_excel(\"restaurant train.xlsx\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "LCiWd4DFyaxC",
        "outputId": "207ef5eb-6e06-43fd-84f4-1abf6e0f3866"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tag</th>\n",
              "      <th>Word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B-Rating</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I-Rating</td>\n",
              "      <td>start</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>O</td>\n",
              "      <td>restaurants</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>O</td>\n",
              "      <td>with</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B-Amenity</td>\n",
              "      <td>inside</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Tag         Word\n",
              "0   B-Rating            2\n",
              "1   I-Rating        start\n",
              "2          O  restaurants\n",
              "3          O         with\n",
              "4  B-Amenity       inside"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMqUVhCEy4SS",
        "outputId": "18df5b90-6ecd-4817-dff4-3fcb25cd2c90"
      },
      "source": [
        "df[\"Tag\"].unique()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['B-Rating', 'I-Rating', 'O', 'B-Amenity', 'I-Amenity', nan,\n",
              "       'B-Location', 'I-Location', 'B-Restaurant_Name',\n",
              "       'I-Restaurant_Name', 'B-Price', 'B-Hours', 'I-Hours', 'B-Dish',\n",
              "       'I-Dish', 'B-Cuisine', 'I-Price', 'I-Cuisine'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIH3mI9iHley"
      },
      "source": [
        ".xlsx to .tsv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEZDirTxGvnp"
      },
      "source": [
        "data_xlsx = pd.read_excel('restaurant train.xlsx', 'Sheet1', index_col=None)\n",
        "\n",
        "#Replace all columns having spaces with underscores\n",
        "data_xlsx.columns = [c.replace(' ', '_') for c in data_xlsx.columns]\n",
        "\n",
        "#Replace all fields having line breaks with space\n",
        "df = data_xlsx.replace('\\n', ' ',regex=True)\n",
        "\n",
        "#Write dataframe into csv\n",
        "df.to_csv('restaurant train TSV.csv', sep='\\t', encoding='utf-8',  index=False, line_terminator='\\r\\n')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbiQ_MFgFDjx"
      },
      "source": [
        "For converting .tsv to json format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMiktIJfDW7D"
      },
      "source": [
        "import json\n",
        "import logging\n",
        "import sys\n",
        "def tsv_to_json_format(input_path,output_path,unknown_label):\n",
        "    try:\n",
        "        f=open(input_path,'r') # input file\n",
        "        fp=open(output_path, 'w') # output file\n",
        "        data_dict={}\n",
        "        annotations =[]\n",
        "        label_dict={}\n",
        "        s=''\n",
        "        start=0\n",
        "        for line in f:\n",
        "            if line[0:len(line)-1]!='.\\tO':\n",
        "                word,entity=line.split('\\t')\n",
        "                s+=word+\" \"\n",
        "                entity=entity[:len(entity)-1]\n",
        "                if entity!=unknown_label:\n",
        "                    if len(entity) != 1:\n",
        "                        d={}\n",
        "                        d['text']=word\n",
        "                        d['start']=start\n",
        "                        d['end']=start+len(word)-1  \n",
        "                        try:\n",
        "                            label_dict[entity].append(d)\n",
        "                        except:\n",
        "                            label_dict[entity]=[]\n",
        "                            label_dict[entity].append(d) \n",
        "                start+=len(word)+1\n",
        "            else:\n",
        "                data_dict['content']=s\n",
        "                s=''\n",
        "                label_list=[]\n",
        "                for ents in list(label_dict.keys()):\n",
        "                    for i in range(len(label_dict[ents])):\n",
        "                        if(label_dict[ents][i]['text']!=''):\n",
        "                            l=[ents,label_dict[ents][i]]\n",
        "                            for j in range(i+1,len(label_dict[ents])): \n",
        "                                if(label_dict[ents][i]['text']==label_dict[ents][j]['text']):  \n",
        "                                    di={}\n",
        "                                    di['start']=label_dict[ents][j]['start']\n",
        "                                    di['end']=label_dict[ents][j]['end']\n",
        "                                    di['text']=label_dict[ents][i]['text']\n",
        "                                    l.append(di)\n",
        "                                    label_dict[ents][j]['text']=''\n",
        "                            label_list.append(l)                          \n",
        "                            \n",
        "                for entities in label_list:\n",
        "                    label={}\n",
        "                    label['label']=[entities[0]]\n",
        "                    label['points']=entities[1:]\n",
        "                    annotations.append(label)\n",
        "                data_dict['annotation']=annotations\n",
        "                annotations=[]\n",
        "                json.dump(data_dict, fp)\n",
        "                fp.write('\\n')\n",
        "                data_dict={}\n",
        "                start=0\n",
        "                label_dict={}\n",
        "    except Exception as e:\n",
        "        logging.exception(\"Unable to process file\" + \"\\n\" + \"error = \" + str(e))\n",
        "        return None\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqWhswooDY-A"
      },
      "source": [
        "tsv_to_json_format(\"restaurant train TSV.csv\",'restaurant train.json','abc')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "3uyHDf3qHxPs",
        "outputId": "0503d3b4-4875-4189-c5de-fd6c1ff6d890"
      },
      "source": [
        "import json\n",
        "f = open('restaurant train.json',)\n",
        "json.load(f)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-d3d45034b629>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'restaurant train.json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzYVRhyuJLMT"
      },
      "source": [
        "json to the format accepted by spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LKqOsavH2vr"
      },
      "source": [
        "import plac\n",
        "import logging\n",
        "import argparse\n",
        "import sys\n",
        "import os\n",
        "import json\n",
        "import pickle\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "ve85noT_IyC5",
        "outputId": "eacffaf1-88e7-46b9-dec4-811bdf2a9f74"
      },
      "source": [
        "@plac.annotations(input_file=(\"Input file\", \"option\", \"i\", str), output_file=(\"Output file\", \"option\", \"o\", str))\n",
        "\n",
        "def main(input_file=None, output_file=None):\n",
        "    try:\n",
        "        training_data = []\n",
        "        lines=[]\n",
        "        with open(input_file, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        for line in lines:\n",
        "            data = json.loads(line)\n",
        "            text = data['content']\n",
        "            entities = []\n",
        "            for annotation in data['annotation']:\n",
        "                point = annotation['points'][0]\n",
        "                labels = annotation['label']\n",
        "                if not isinstance(labels, list):\n",
        "                    labels = [labels]\n",
        "\n",
        "                for label in labels:\n",
        "                    entities.append((point['start'], point['end'] + 1 ,label))\n",
        "\n",
        "\n",
        "            training_data.append((text, {\"entities\" : entities}))\n",
        "\n",
        "        print(training_data)\n",
        "\n",
        "        with open(output_file, 'wb') as fp:\n",
        "            pickle.dump(training_data, fp)\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.exception(\"Unable to process \" + input_file + \"\\n\" + \"error = \" + str(e))\n",
        "        return None\n",
        "if __name__ == '__main__':\n",
        "    plac.call(main)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] [-i None] [-o None]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-d3eda699-61e5-46bc-8723-52cf74f2597b.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp-N_RQLJfv9"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0n_NpVjKAsG"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "-vC3KuxkKXvH",
        "outputId": "2ebbc0ae-c059-4274-c108-51f46b907c10"
      },
      "source": [
        "from __future__ import unicode_literals, print_function\n",
        "import pickle\n",
        "import plac\n",
        "import random\n",
        "from pathlib import Path\n",
        "import spacy\n",
        "from spacy.util import minibatch, compounding\n",
        "\n",
        "\n",
        "# New entity labels\n",
        "# Specify the new entity labels which you want to add here\n",
        "LABEL = ['B-Rating', 'I-Rating', 'O', 'B-Amenity', 'I-Amenity',\n",
        "       'B-Location', 'I-Location', 'B-Restaurant_Name',\n",
        "       'I-Restaurant_Name', 'B-Price', 'B-Hours', 'I-Hours', 'B-Dish',\n",
        "       'I-Dish', 'B-Cuisine', 'I-Price', 'I-Cuisine']\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "# Loading training data \n",
        "with open ('restaurant train.json', 'rb') as fp:\n",
        "    TRAIN_DATA = pickle.load(fp)\n",
        "\n",
        "@plac.annotations(\n",
        "    model=(\"Model name. Defaults to blank 'en' model.\", \"option\", \"m\", str),\n",
        "    new_model_name=(\"New model name for model meta.\", \"option\", \"nm\", str),\n",
        "    output_dir=(\"Optional output directory\", \"option\", \"o\", Path),\n",
        "    n_iter=(\"Number of training iterations\", \"option\", \"n\", int))\n",
        "\n",
        "def main(model=None, new_model_name='new_model', output_dir=None, n_iter=10):\n",
        "    \"\"\"Setting up the pipeline and entity recognizer, and training the new entity.\"\"\"\n",
        "    if model is not None:\n",
        "        nlp = spacy.load(model)  # load existing spacy model\n",
        "        print(\"Loaded model '%s'\" % model)\n",
        "    else:\n",
        "        nlp = spacy.blank('en')  # create blank Language class\n",
        "        print(\"Created blank 'en' model\")\n",
        "    if 'ner' not in nlp.pipe_names:\n",
        "        ner = nlp.create_pipe('ner')\n",
        "        nlp.add_pipe(ner)\n",
        "    else:\n",
        "        ner = nlp.get_pipe('ner')\n",
        "\n",
        "    for i in LABEL:\n",
        "        ner.add_label(i)   # Add new entity labels to entity recognizer\n",
        "\n",
        "    if model is None:\n",
        "        optimizer = nlp.begin_training()\n",
        "    else:\n",
        "        optimizer = nlp.entity.create_optimizer()\n",
        "\n",
        "    # Get names of other pipes to disable them during training to train only NER\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
        "        for itn in range(n_iter):\n",
        "            random.shuffle(TRAIN_DATA)\n",
        "            losses = {}\n",
        "            batches = minibatch(TRAIN_DATA, size=compounding(4., 32., 1.001))\n",
        "            for batch in batches:\n",
        "                texts, annotations = zip(*batch)\n",
        "                nlp.update(texts, annotations, sgd=optimizer, drop=0.35,\n",
        "                           losses=losses)\n",
        "            print('Losses', losses)\n",
        "\n",
        "    # Test the trained model\n",
        "    test_text = 'Gianni Infantino is the president of FIFA.'\n",
        "    doc = nlp(test_text)\n",
        "    print(\"Entities in '%s'\" % test_text)\n",
        "    for ent in doc.ents:\n",
        "        print(ent.label_, ent.text)\n",
        "\n",
        "    # Save model \n",
        "    if output_dir is not None:\n",
        "        output_dir = Path(output_dir)\n",
        "        if not output_dir.exists():\n",
        "            output_dir.mkdir()\n",
        "        nlp.meta['name'] = new_model_name  # rename model\n",
        "        nlp.to_disk(output_dir)\n",
        "        print(\"Saved model to\", output_dir)\n",
        "\n",
        "        # Test the saved model\n",
        "        print(\"Loading from\", output_dir)\n",
        "        nlp2 = spacy.load(output_dir)\n",
        "        doc2 = nlp2(test_text)\n",
        "        for ent in doc2.ents:\n",
        "            print(ent.label_, ent.text)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    plac.call(main)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "EOFError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-493138b3df58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Loading training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'restaurant train.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mTRAIN_DATA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m @plac.annotations(\n",
            "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GnO75IeLJHb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}